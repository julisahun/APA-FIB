{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1f12f; Javier Bejar - APA/GEI/FIB/UPC (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "# !pip install pandas --user --upgrade --quiet\n",
    "# !pip install numpy --user --upgrade --quiet\n",
    "# !pip install scipy --user --upgrade --quiet\n",
    "# !pip install statsmodels --user --upgrade --quiet\n",
    "# !pip install seaborn --user --upgrade --quiet\n",
    "# !pip install matplotlib --user --upgrade --quiet\n",
    "# !pip install scikit-learn --user --upgrade \n",
    "# !pip install imblearn --upgrade --user --quiet\n",
    "# !pip install scikit-optimize --user --quiet\n",
    "!pip install dtreeviz --upgrade --user --quiet\n",
    "!pip install apafib --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "show_html = lambda html: display(HTML(html))\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "init_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APA - Laboratorio - Sesión 7\n",
    "## Árboles de decisión - Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay,\\\n",
    "                  classification_report,  RocCurveDisplay, PrecisionRecallDisplay,\\\n",
    "                     f1_score, make_scorer, accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier,ExtraTreesClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, CategoricalNB, MultinomialNB\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from yellowbrick.classifier import ROCAUC\n",
    "from yellowbrick.classifier.rocauc import roc_auc\n",
    "from skopt import BayesSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import  RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "import eli5\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "import warnings\n",
    "from apafib import load_attrition\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(clf, X_test, y_test, nclf, df):\n",
    "    df.loc[nclf,'test acc'] = accuracy_score(y_test, clf.predict(X_test))\n",
    "    df.loc[nclf,'test f1 score (0)'] = f1_score(y_test, clf.predict(X_test), pos_label=0)\n",
    "    df.loc[nclf,'test f1 score (1)'] = f1_score(y_test, clf.predict(X_test), pos_label=1)\n",
    "    df.loc[nclf,'test f1 score (W)'] = f1_score(y_test, clf.predict(X_test), average='macro')\n",
    "    df.loc[nclf,'ROC AUC'] = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    return df\n",
    "\n",
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sección 1: Employee Attrition for Healthcare\n",
    "\n",
    "Entre las muchas aplicaciones prácticas de aprendizaje, una de ellas es la predicción de si alguien tomará cierta decisión dada su historia, por ejemplo si alguien va a dejar de ser cliente o va a dejar su trabajo, es lo que se conoce como tasa de abandono (en inglés churn rate o attrition rate).\n",
    "\n",
    "Este es un conjunto de datos ficticio de personal de salud creado por IBM como demostración que usaremos para probar modelos de árboles de decisión y combinación de clasificadores (https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset).\n",
    "\n",
    "El elemento diferente que tiene este tipo de aplicación es que habitualmente hay un desequilibrio entre las clases ya que a no ser que pase algo raro, la gente no deja una compañia en masa.\n",
    "\n",
    "Cargaremos los datos y haremos alguna visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_attrition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro problema es binario, podemos ver que hay un gran desbalance entre las clases ~ 1:6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = [str(v) for v in sorted(data['Attrition'].unique())]\n",
    "data['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproceso\n",
    "\n",
    "Como trabajaremos con árboles de decisión transformaremos todos los atributos a valores numéricos. Eliminaremos también la variable `Over18`, `StandardHours` y `EmployeeCount` ya que todos sus valores son el mismo y `EmployeeId` que es identificador. Este conjunto de datos no tiene valores perdidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Over18', 'EmployeeCount', 'StandardHours', 'EmployeeNumber'],  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    if data[c].dtype.kind == 'O':\n",
    "        data[c] = data[c].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos dividir nuestros datos en entrenamiento y test. No hace falta normalización ya que trabajaremos con árboles de decisión, en este modelo no importa el rango de las variables, además si no las transformamos podremos interpretar directamente el árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.loc[:,data.columns!='Attrition']\n",
    "y= data.loc[:,'Attrition']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10,3,figsize=(15,28))\n",
    "\n",
    "X_train_frame = pd.DataFrame(X_train)\n",
    "X_train_frame.columns=X.columns\n",
    "for i, c in enumerate(X.columns):\n",
    "    ax = axes.reshape(-1)[i]\n",
    "    b = sns.histplot(x=c,data=X_train_frame,ax=ax, hue=y_train, palette='tab10')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar los datos con PCA aunque los datos no son gausianos, la mayoria son atributos discretos y los que son continuos no siguen esa distribución en su mayoría (excepto Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6));\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ ,alpha=0.8,marker='.',label=\"Variancia Explicada\");\n",
    "y_label = plt.ylabel('Variancia explicada');\n",
    "x_label = plt.xlabel('Componentes');\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',marker='.',\n",
    "         label=\"Variancia explicada acumulativa\");\n",
    "plt.legend();\n",
    "plt.title('Porcentaje de variancia explicada por componente');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que dos componentes se llevan prácticamente el 100% de la variancia, aunque en la visualización de estos dos componentes podemos ver que no hay mucha separación entre las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "plt.figure(figsize=(8,8));\n",
    "sns.scatterplot(x=X_train_pca[:,0], y=X_train_pca[:,1], hue=y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota:\n",
    "\n",
    "Estas dos variables controlan el número de particiones de validación cruzada que se usan en el ajuste de los modelos y el número de modelos que prueba la búsqueda bayesiana, por defecto se usa 5 y 40. Aparte de esto, la aleatoriedad que interviene en los modelos cambiará los resultados finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=10\n",
    "iter=40\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión\n",
    "\n",
    "Empezaremos ajustando un árbol de decisión a los datos explorando los diferentes hiper parámetros del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'min_samples_leaf':[1,2,3,5,10], \n",
    "         'splitter': ['best', 'random'], \n",
    "         'max_leaf_nodes':[5, 10, 20, 30]}\n",
    "\n",
    "dt =  DecisionTreeClassifier(random_state=0)\n",
    "dt_bs =  BayesSearchCV(dt,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "dt_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(dt_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dt_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(dt_bs, X_test, y_test, 'DTree base', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que lo hacemos muy bien en la clase negativa a costa de hacerlo muy mal en la clase positiva, dado que precisamente tenemos más interes en su predicción no es un modelo demasiado bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(dt_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la curva ROC podemos ver que si cambiaramos el punto de decisión podríamos llegar a algo más de un 60% de verdaderos positivos con un numero de falsos positivos de alrededor del 25%. Esto supondía alrededor de 100 ejemplos de la clase negativa clasificados como clase positiva, habría que ver si tiene sentido en el problema y el coste que supone equivocarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(dt_bs, X_test,y_test, pos_label=1, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar el árbol resultante, pero hemos de tener en cuenta que cambios en como seleccionamos el conjunto de entrenamiento cambiarán bastante las decisiones del árbol. Podemos ver que es bastante sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreeviz(dt_bs.best_estimator_, scale=1.5,\n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='Attrition',\n",
    "               feature_names=[c for c in data.columns if c!='Attrition'],\n",
    "               class_names=cls,\n",
    "               title=\"Decision Tree - Baseline\",\n",
    "               orientation='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen diferentes cosas que podemos hacer para incrementar la precisión y recuperación del modelos.\n",
    "\n",
    "- Asignar diferente peso a cada una de las clases de manera que intente reducir el error de la que nos interesa\n",
    "- Remuestrear las clases de manera que tengamos un conjunto de entrenamiento con más balance entre clases aumentando la clase minoritara o disminuyendo la mayoritaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peso de las clases\n",
    "\n",
    "El modelo de árbol de decisión (y también otros modelos) permite balancear las clases a partir de su probabilidad en el conjunto de datos, de manera que podamos asignarles un peso diferente. Podemos poner la relación de pesos que queramos, dependiendo de este valor podemos tener resultados en los que la clase minoritaria mejora su clasificación.\n",
    "\n",
    "Hay que tener cuidado con este peso ya que no garantiza que el clasificador lo haga bien aunque aumentemos mucho el peso de la clase minoritaria (el valor que hay esta puesto _mágicamente_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'min_samples_leaf':[1,2,3,5,10], \n",
    "         'splitter': ['best', 'random'], \n",
    "         'max_leaf_nodes':[5, 10, 20, 30]}\n",
    "\n",
    "dt =  DecisionTreeClassifier(random_state=0, class_weight={0:1,1:5.5})\n",
    "dt_cw_bs =  BayesSearchCV(dt,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "dt_cw_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(dt_cw_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cambiar los pesos ha reducido el acierto global del modelo ya que hemos empezado a predecir mejor la clase que nos importa más. En este caso acertamos bastantes más  ejemplos de esa clase, pero con un gran número de falsos positivos. En algunas aplicaciones esto puede ser un problema. También habría que sopesar si la caida en acierto nos compensa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dt_cw_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(dt_cw_bs, X_test, y_test, 'DTree class weights', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(dt_cw_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El AUC no ha mejorado en este caso, pero puede depender de la muestra concreta con la que entrenemos el árbol, este es un problema que aparecerá en cualquier modelo que hagamos con un solo árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(dt_cw_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT w\");\n",
    "RocCurveDisplay.from_estimator(dt_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el árbol se ha vuelto mucho más complejo para poder distinguir ese número extra de ejemplos de la clase positiva. Tampoco coindide en como este árbol toma decisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreeviz(dt_cw_bs.best_estimator_, scale=1.5,\n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='Attrition',\n",
    "               feature_names=[c for c in data.columns if c!='Attrition'],\n",
    "               class_names=cls,\n",
    "               title=\"Decision Tree - Class weights\",\n",
    "               orientation='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submuestreo de la clase mayoritaria\n",
    "\n",
    "La libreria imblearn tiene diferentes algoritmos para el tratamiento de palabras con desbalance de clases.\n",
    "\n",
    "Empezaremos por un método que reduce la muestra de la clase mayoritaria para que la relación que hay entre las dos sea un valor dado. Aprovecharemos que podemos juntar diferentes pasos en `Pipelines` para añadir todo el proceso al ajuste de hiperparámetros.\n",
    "\n",
    "La posibilidad de hacer `Pipelines` la tiene también scikit-learn, pero las funciones de imblearn tienen una signatura diferente y hace falta usar el objeto específico de esta librería para que funcione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'dt__criterion':['gini', 'entropy'], \n",
    "         'dt__max_depth':[None, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'dt__min_samples_leaf':[1,2,3,5,10], \n",
    "         'dt__splitter': ['best', 'random'], \n",
    "         'dt__max_leaf_nodes':[5, 10, 20, 30],\n",
    "         'rus__sampling_strategy':np.linspace(0.2,0.5,16)}\n",
    "\n",
    "dt =  DecisionTreeClassifier(random_state=0)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "dt_us= Pipeline([('rus', rus), ('dt', dt)])\n",
    "dt_us_bs =  BayesSearchCV(dt_us,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "dt_us_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(dt_us_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que con esta estrategia hemos ganado algo respecto al árbol original, perdiendo un poco en el acierto global en el test, pero mejorando  en la clase que nos interesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dt_us_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(dt_us_bs, X_test, y_test, 'DTree under samp', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consecuencia aumentamos los que acertamos en la clase positiva, pero también aumentanlos falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(dt_us_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es muy parecida a la del modelo incial, se ha reducido algo AUC, tenemos basicamente los mismos puntos de corte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(dt_us_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT under\");\n",
    "RocCurveDisplay.from_estimator(dt_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El árbol esta en un punto intermedio de complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreeviz(dt_us_bs.best_estimator_['dt'], scale=1.5,\n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='Attrition',\n",
    "               feature_names=[c for c in data.columns if c!='Attrition'],\n",
    "               class_names=cls,\n",
    "               title=\"Decision Tree - Under sampling\",\n",
    "               orientation='LR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super muesteo de la clase minoritaria\n",
    "\n",
    "En este caso se añaden muestras repetidas de la clase minoritaria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'dt__criterion':['gini', 'entropy'], \n",
    "         'dt__max_depth':[None, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'dt__min_samples_leaf':[1,2,3,5,10], \n",
    "         'dt__splitter': ['best', 'random'], \n",
    "         'dt__max_leaf_nodes':[5, 10, 20, 30],\n",
    "         'ros__sampling_strategy':np.linspace(0.2,0.5,16)}\n",
    "\n",
    "dt =  DecisionTreeClassifier(random_state=0)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "dt_os= Pipeline([('ros', ros), ('dt', dt)])\n",
    "dt_os_bs =  BayesSearchCV(dt_os,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "dt_os_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(dt_os_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos sale un modelo exactamente igual que el original, no parece que replicar instancias haya ayudado al modelo. Por los resultados de la exploración el oversampling que da mejores resultados deja practicamente el tamaño de la clase positiva como está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dt_os_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(dt_os_bs, X_test, y_test, 'DTree over samp', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(dt_os_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(dt_os_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='DT over');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreeviz(dt_os_bs.best_estimator_['dt'], scale=1.5,\n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='Attrition',\n",
    "               feature_names=[c for c in data.columns if c!='Attrition'],\n",
    "               class_names=cls,\n",
    "               title=\"Decision Tree - Over Sampling\",\n",
    "               orientation='LR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super muestreo de la clase mayoritaria con SMOTE\n",
    "\n",
    "SMOTE es un algoritmo de super muestreo que en lugar de repetir ejemplos ya existentes genera ejemplos nuevos perturbando los ya existentes asumiendo que estos ejemplos pertenecerán a la misma clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'dt__criterion':['gini', 'entropy'], \n",
    "         'dt__max_depth':[None, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "         'dt__min_samples_leaf':[1,2,3,5,10], \n",
    "         'dt__splitter': ['best', 'random'], \n",
    "         'dt__max_leaf_nodes':[5, 10, 20, 30],\n",
    "          'smote__sampling_strategy':np.linspace(.2,0.5,16)}\n",
    "\n",
    "dt =  DecisionTreeClassifier(random_state=0)\n",
    "smt = SMOTE(random_state=0)\n",
    "dt_sm= Pipeline([('smote', smt), ('dt', dt)])\n",
    "dt_sm_bs =  BayesSearchCV(dt_sm,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "dt_sm_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(dt_sm_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de este método no son mejores, incluso han empeorado  el resultado en la clase que nos interesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(dt_sm_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(dt_sm_bs, X_test, y_test, 'DTree SMOTE', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(dt_sm_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la AUC es también peor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(dt_sm_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT SMOTE\");\n",
    "RocCurveDisplay.from_estimator(dt_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtreeviz(dt_sm_bs.best_estimator_['dt'], scale=1.5,\n",
    "               x_data=X_train,\n",
    "               y_data=y_train,\n",
    "               target_name='Attrition',\n",
    "               feature_names=[c for c in data.columns if c!='Attrition'],\n",
    "               class_names=cls,\n",
    "               title=\"Decision Tree - SMOTE\",\n",
    "               orientation='LR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de clasificadores basadas en árboles de decisióm\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Una ventaja de utilizar combinación de clasificadores basados en árboles es que cada uno de los árboles ve el conjunto de datos de una manera diferente ya sea porque se muestrean los atributos o los ejemplos, eso puede ayudar a corregir un problema de desbalance en los datos.\n",
    "\n",
    "Comenzaremos con random forest que combina árboles donde cada uno selecciona una muestra con reposición del conjunto de datos, asi que en nuestro caso el desbalance en cada árbol será diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10]}\n",
    "\n",
    "rf =  RandomForestClassifier(random_state=0)\n",
    "rf_bs =  BayesSearchCV(rf,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "rf_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rf_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso estamos obteniendo resultados peores en la clase que nos interesa con un acierto global parecido al arbol inicial. Eso si, ahora tenemos muchos más árboles, por lo que el coste de inferencia se ha multiplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rf_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(rf_bs, X_test, y_test, 'Random Forest', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos ganado algo, pero no parece que sea demasiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(rf_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero si miramos la curva ROC, podemos ver que la AUC está muy por encima del mejor modelo con un solo árbol de decision, tenemos más puntos de corte donde elegir y ahora el tener 60% de vp nos da un punto de corte por alrededor del 20% de fp, por lo que tenemos un modelo mejor aunque por los resultados del informe de clasificación no lo pareciera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");\n",
    "RocCurveDisplay.from_estimator(dt_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"DT\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest con peso de las clases \n",
    "\n",
    "Dado que el cambiar los pesos de las clases no mejoró el modelo con un árbol podemos ver si pasa lo mismo con la combinación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10]}\n",
    "\n",
    "rf =  RandomForestClassifier(random_state=0, class_weight={0:1,1:5.5})\n",
    "rf_cw_bs =  BayesSearchCV(rf,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "rf_cw_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(rf_cw_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que efectivamente es el caso, hemos subido el resultado en la clase positiva sin afectar casi a la clase negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(rf_cw_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(rf_cw_bs, X_test, y_test, 'Random Forest CW', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(rf_cw_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver también en la curva ROC que tenemos el corte del 60% de vp por debajo del 20% de fp podemos obtener un porcentaje parecido de vp, en esa parte de la curva es mejor que el modelo anterior aunque tenga un ROC algo peor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(rf_cw_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='RF w');\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extremely Randomized Trees\n",
    "\n",
    "Los Extremely Randomized Trees llevan la randomización un paso más allá generando los árboles prácticamente al azar. Esto nos obligará muchas veces a necesitar más árboles para obtener un resultado equivalente a random forest, pero con la posibilidad de mejores resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'criterion':['gini', 'entropy'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10]}\n",
    "\n",
    "et =  ExtraTreesClassifier(random_state=0)\n",
    "et_bs =  BayesSearchCV(rf,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "et_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(et_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(et_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(et_bs, X_test, y_test, 'Extra Trees CW', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hemos obtenido un modelo diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(et_bs, X_test,y_test, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC tiene resultados parecidos, pero da mejores puntos de corte al principio de la curva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(et_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='ExT')\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "\n",
    "Gradient Boosting es un modelo que se construye additivamente, cada modelo se especializa en el residuo del árbol anterior.\n",
    "\n",
    "La clasificación se resuelve por regresión asumiendo que el clasificador base es probabiliístico y lo que hacermos es hacer regresión sobre esas probabilidades. Dado que el modelo es aditivo, no tiene sentido el manipular los pesos de las clases, esto se hace ya automáticamente, si hay una clase más difícil el siguiente modelo le dará más peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': [5,10,25,40, 50, 75,100, 200], \n",
    "         'loss':['log_loss', 'exponential'], \n",
    "         'criterion':['friedman_mse', 'squared_error'], \n",
    "         'max_depth':[None, 1, 2, 3,  5,  8, 9,10,15],\n",
    "         'min_samples_leaf':[1,2,3,5,10], \n",
    "         'learning_rate':[0.1,0.5, 1,3, 5, 10, 15]}\n",
    "\n",
    "gb =  GradientBoostingClassifier(random_state=0,n_iter_no_change=5)\n",
    "gb_bs =  BayesSearchCV(gb,param,n_iter=iter, cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "gb_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(gb_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es bueno, aqui dependiendo de la semilla de numeros aleatorios puede estar alrededor del resultado del mejor modelo hasta ahora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gb_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(gb_bs, X_test, y_test, 'Gradient Boosting', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(gb_bs, X_test,y_test, ax=plt.subplot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es distinta, aunque esta en línea con los otros modelos los puntos de corte son diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='GB');\n",
    "RocCurveDisplay.from_estimator(rf_cw_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='RF w');\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['test acc', 'ROC AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos observar todos los modelos que hemos ido generando. Si nos fijamos en la AUC y el acierto, dependiendo de la aleatoriedad tendremos resultados más o menos parecidos, aunque en alguna ocasión alguno de ellos puede diferenciarse.\n",
    "\n",
    "\n",
    "Habría que ver si la diferencia es significativa, eso involucraría hacer una validación cruzada anidada, en la que dejaramos fuera diferentes muestras de test para poder tener una distribución de valores y usar un test estadístico sobre la media de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembles generales\n",
    "\n",
    "Obviamente no solo podemos combinar árboles de decisión, podemos combinar varios modelos que nos den visiones diferentes del problema y ver si eso mejora el resultado. Claramente no tenemos ninguna garantia de que eso sea así, es posible que todos los modelos que usemos acaben convergiendo a una frontera de decisión similar y que la combinación no nos ayude\n",
    "\n",
    "Empezaremos por añadir dos clasificadores diferentes que podamos combinar con los de árboles de decisión, Regresión logística y Naive Bayes Gausiano. Este último no encaja perfectamente ya que tenemos atributos nominales, pero eso podría ayudar a obtener diversidad en los clasificadores.\n",
    "\n",
    "Empezaremos por regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'penalty':['l1', 'l2'], 'C':10**np.linspace(-3,3,101, endpoint=True)}\n",
    "lr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "lr_bs =  BayesSearchCV(lr,param,n_iter=iter,cv=cv, n_jobs=-1, refit=True, random_state=0)\n",
    "lr_bs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(lr_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorprendentemente el resultado es mejor que el de todos los modelos que hemos probado hasta ahora. Esto nos debería hacer pensar que cuando abordamos un problema tiene sentido el empezar por modelos más sencillos que nos permitan ver cuál es el mínimo modelo que podemos obtener y a partir de el ver si modelos más complejos merecen la pena. En este caso tenemos un modelo que solo necesita un numero lineal de pesos que ocupa bastante menos que los ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(lr_bs.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(lr_bs, X_test, y_test, 'Logistic Regression', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver la mejora en el número de vp respecto al de fp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(lr_bs, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es ligeramente mejor, también podemos llegar a mas de 70% de vp sin llegar al 20% del fp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(lr_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='LR');\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='GB');\n",
    "RocCurveDisplay.from_estimator(rf_cw_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='RF w');\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar ahora con Naïve Bayes, en este modelo no hay ningún parámetro que ajustar y como hemos comentado los datos no cumplen exactamente lo que asume el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "print(np.mean(cross_val_score(gnb,X_train,y_train,cv=cv)))   \n",
    "gnb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No podíamos esperar que este modelo fuera mejor, pero sorprendentemente (o no tanto) obtiene un buen resultado en la clase positiva, eso nos dice que al menos este clasificador tiene una visión diferente de los datos. Su acierto global es peor que el del resto de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(gnb.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(gnb, X_test, y_test, 'Naive Bayes', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay bastantes ejemplos de la clase positiva bien clasificados y con un mejor ratio con los falsos positivos que muchos de los modelos de árboles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(gnb, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la curva ROC podemos ver que obtener cerca de un 70% de vp da un ratio de fp de alrededor del 20% que es mejor que muchos de los modelos de árboles y el AUC es similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(gnb, X_test,y_test, pos_label=1, ax=plt.subplot(), name='GaussNB');\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='GB');\n",
    "RocCurveDisplay.from_estimator(rf_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name=\"RF\");\n",
    "RocCurveDisplay.from_estimator(lr_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='LR');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['test acc', 'ROC AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "\n",
    "Empezaremos haciendo un clasificador que corresponda la votación entre varios clasificadores\n",
    "\n",
    "El primero consistira en gradient boosting (podemos elegir el que mejor resultado nos de según el resultado que nos de la ejecución, pero puede no haber una gran diferencia) con regresión logística, usaremos votacion soft para poder usar las probabilidades de la clasificacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs1 = VotingClassifier([('gb', gb_bs.best_estimator_),\n",
    "                        ('lr', lr_bs.best_estimator_)],voting='soft', n_jobs=1)\n",
    "print(np.mean(cross_val_score(vs1,X_train,y_train,cv=cv)))                             \n",
    "vs1.fit(X_train, y_train);                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver hemos conseguido mejorar algo tanto en la clasificacion global como en el f1 de la clase positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(vs1.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(vs1, X_test, y_test, 'Voting GB+LR', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso se puede ver en los conteos de la matriz de confusión hemos disminuido ligeramente los fp y aumentado los vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(vs1, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La curva ROC es parecida a la de LR habría que ver exactamente el ratio vp/fp en los puntos de corte, pero podemos ver que la AUC ha aumentado ligeramente, asi que este modelo es mejor que los que hemos obtenido hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(vs1, X_test,y_test, pos_label=1, ax=plt.subplot(), name='V GB+LR');\n",
    "RocCurveDisplay.from_estimator(gb_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='GB');\n",
    "RocCurveDisplay.from_estimator(lr_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='LR');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que pasa si le añadimos Naive Bayes (para poder romper posibles empates si el que los hubiera) y además aprovechar que las decisiones de este modelo son diferentes y más sesgadas a la clase minoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs2 = VotingClassifier([('gb', gb_bs.best_estimator_),\n",
    "                        ('nb', gnb),   \n",
    "                        ('lr', lr_bs.best_estimator_)],voting='soft', n_jobs=1)\n",
    "print(np.mean(cross_val_score(vs2,X_train,y_train,cv=cv)))                             \n",
    "vs2.fit(X_train, y_train);                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el resultado varia sesgandolo hacia la clase positiva, el resultado global de acierto es prácticamente el mismo, pero tiene el f1 para la clase positiva mejor de todos los que hemos obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(vs2.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(vs2, X_test, y_test, 'Voting GB+GNB+LR', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso se puede ver en la matriz de confusión, hemos perdido algunos de la clase negativa y los hemos ganado en la positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(vs2, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui también deberíamos examinar los puntos de corte, la AUC es muy parecida a la de LR, las curvas son mejores en diferentes partes del limite de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(vs2, X_test,y_test, pos_label=1, ax=plt.subplot(), name='V GB+LR+GNB');\n",
    "RocCurveDisplay.from_estimator(lr_bs, X_test,y_test, pos_label=1, ax=plt.subplot(), name='LR');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superponiendo los dos ensembles podemos ver que la curva del primer modelo es superior prácticamente en todo su recorrido, el corte del mas o menos 70%/20% que hemos ido observando es prácticamente idéntico, asi que el primer modelo sería un poco mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(vs2, X_test,y_test, pos_label=1, ax=plt.subplot(), name='V GB+LR+GNB');\n",
    "RocCurveDisplay.from_estimator(vs1, X_test,y_test, pos_label=1, ax=plt.subplot(), name='V GB+LR');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Finalmente podemos probar stacking, en este caso aprendemos a como combinar las decisiones de los clasificadores, sobre los resulados ponemos una regresión logística (el modelo por defecto) en lugar de simplemente hacer la media de las probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = StackingClassifier([('gb', gb_bs.best_estimator_),\n",
    "                          ('lr', lr_bs.best_estimator_)],\n",
    "                          cv=cv, n_jobs=1)\n",
    "print(np.mean(cross_val_score(st1,X_train,y_train,cv=cv)))                             \n",
    "st1.fit(X_train, y_train);                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay mucha diferencia, hemos ganado algo de acierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(st1.predict(X_test), y_test,target_names=cls))\n",
    "results_df = save_results(st1, X_test, y_test, 'Stacking GB+LR', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(st1, X_test,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si superponemos las dos curvas ROC vemos que son prácticamente idénticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "RocCurveDisplay.from_estimator(st1, X_test,y_test, pos_label=1, ax=plt.subplot(), name='S GB+LR');\n",
    "RocCurveDisplay.from_estimator(vs1, X_test,y_test, pos_label=1, ax=plt.subplot(), name='V GB+LR');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo final está a un nivel parecido al voting, como comentamos antes habría que hacer validación cruzada anidada para obtener una distribución y comprobar si realmente hay una diferencia estadística entre modelos.\n",
    "\n",
    "A falta de ella, podemos decidirnos por el modelos con mejores valores en todos los criterios.\n",
    "\n",
    "Si queremos un modelo sencillo ligeramente peor nos podemos dedicidir por la regresión logística\n",
    "\n",
    "Si queremos un modelo que esté ligeramenente sesgado hacia la clase positiva el modelo de votación que combina los tres mejores clasificadores sería nuestra opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['test acc', 'ROC AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Running time {timedelta(seconds=(time() - init_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
