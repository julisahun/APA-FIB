{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf15854f",
   "metadata": {},
   "source": [
    "&#x1f12f; Raquel Pérez & Javier Bejar - APA/GEI/FIB/UPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3bf4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "# !pip3 install pandas --user --upgrade --quiet\n",
    "# !pip3 install numpy --user --upgrade --quiet\n",
    "# !pip3 install scipy --user --upgrade --quiet\n",
    "# !pip3 install statsmodels --user --upgrade --quiet\n",
    "# !pip3 install seaborn --user --upgrade --quiet\n",
    "# !pip3 install matplotlib --user --upgrade --quiet\n",
    "# !pip3 install scikit-learn --user --upgrade \n",
    "# !pip install scikit-optimize --user --quiet\n",
    "!pip install apafib --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf134081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "init_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc71b19f",
   "metadata": {},
   "source": [
    "# APA - Laboratorio - Sesión 3\n",
    "## Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split,  KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import set_config\n",
    "\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "\n",
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set()\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b2c4f",
   "metadata": {},
   "source": [
    "## SECCIÓN 1: Los datos\n",
    "\n",
    "En esta sesión de laboratorio vamos a predecir la esperanza de vida de diferentes países durante diferentes años dados diferentes marcadores socioeconómicos.\n",
    "\n",
    "Como puede notar, este conjunto de datos tiene un componente temporal (la esperanza de vida en un país un año puede tener una correlación con los años anteriores y posteriores). Normalmente, este componente temporal debe tenerse en cuenta (rompe la suposición de iid, por ejemplo), sin embargo, por simplicidad, lo ignoraremos. El tratamiento del componente temporal está fuera del alcance del curso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from file\n",
    "try:\n",
    "    from apafib import load_life_expectancy\n",
    "    life_expectancy_data = load_life_expectancy()\n",
    "except:\n",
    "    life_expectancy_data = pd.read_csv('Life_Expectancy_Data.csv')\n",
    "\n",
    "# remove spaces and symbols to avoid problems with statsmodel GLM\n",
    "life_expectancy_data.columns = [c.lower().strip().replace(' ','_').replace('/','_').replace('-','_') \n",
    "                                for c in life_expectancy_data.columns] \n",
    "\n",
    "# change the type of categorical variables into category\n",
    "categorical_columns = list(life_expectancy_data.dtypes[life_expectancy_data.dtypes == 'O'].index.values)\n",
    "for column in categorical_columns:\n",
    "    life_expectancy_data[column] = life_expectancy_data[column].astype('category')\n",
    "\n",
    "# peak into the data\n",
    "life_expectancy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acc3f1",
   "metadata": {},
   "source": [
    "Siempre es una buena idea hacer una pequeña exploración de los datos. Los datos reales necesitan procesamiento previo y es importante comprender su conjunto de datos para poder tomar buenas decisiones de diseño.\n",
    "\n",
    "Nuestro conjunto de datos tiene 2938 muestras y 21 variables predictivas. Nuestro objetivo es `life_expectancy`.\n",
    "\n",
    "Vamos a hacer una visualización rápida de los datos. En esta visualización usamos histogramas para mostrar la distribución de las variables numéricas y diagramas de barras para las categóricas.\n",
    "\n",
    "Con este tipo de visualizaciones fáciles, podemos ver mucha información relevante sobre nuestros datos, como si tenemos nuestros valores o si alguna variable se ha codificado incorrectamente, o si \"parece\" lo suficientemente gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(7,3,figsize=(15,30))\n",
    "\n",
    "# We will not plot country because it has too many categories.\n",
    "for i, c in enumerate(life_expectancy_data.columns[1:]):\n",
    "    ax = axes.reshape(-1)[i]\n",
    "    if life_expectancy_data[c].dtype.kind == 'O':\n",
    "        a = sns.countplot(x=c,data=life_expectancy_data,ax=ax)\n",
    "    else:\n",
    "        b = sns.histplot(x=c,data=life_expectancy_data,ax=ax)\n",
    "    t = ax.set_title(c)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6600838",
   "metadata": {},
   "source": [
    "Si no podéis representar una variable categórica de manera efectiva porque tiene demasiadas categorías, podéis verificarla con la función `value_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(life_expectancy_data['country'].unique())\n",
    "life_expectancy_data['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff60035",
   "metadata": {},
   "source": [
    "Otra forma de visualizar cada variable (numérica) es usar la función de histograma de `pandas` en todo el marco de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb173ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy_data.hist(figsize=(26,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a074b1",
   "metadata": {},
   "source": [
    "## Valores perdidos\n",
    "\n",
    "Ahora que sabemos cómo se ven nuestros datos, es una buena idea verificar cuántos valores perdidos tenemos en cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f036cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_expectancy_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad078ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "life_expectancy_data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0b604",
   "metadata": {},
   "source": [
    "Podemos utilizar toda esta información para diseñar una metodología de preprocesamiento eficaz y elegir un modelo adecuado adaptado a nuestros datos. Para mostrar cuán importante es esto, haremos dos preprocesamientos diferentes:\n",
    "\n",
    "* **Preprocesamiento genérico**: simplemente transforma los datos en algo que un modelo puede procesar sin dar errores. Ignorando por completo las peculiaridades del conjunto de datos.\n",
    "\n",
    "* **Preprocesamiento Específico**: Preprocesamiento adaptado a los modelos que estaremos utilizando y las particularidades de los datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f0a6ad",
   "metadata": {},
   "source": [
    "### Protocolo de muestreo y prueba\n",
    "\n",
    "Usaremos dos particiones de datos (entrenamiento y prueba) con validación cruzada sobre la partición de entrenamiento para decidir los hiperparámetros. \n",
    "\n",
    "Explicaremos en detalle la validación cruzada en la sección 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = life_expectancy_data.loc[:,life_expectancy_data.columns != 'life_expectancy']\n",
    "y = life_expectancy_data['life_expectancy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07e28d",
   "metadata": {},
   "source": [
    "## SECCIÓN 3: Regresión lineal (con mínimo preprocesamiento de los datos)\n",
    "\n",
    "Esta es la sesión de laboratorio de Regresión Lineal. Por esta razón, utilizaremos los modelos de regresión lineal, regresión LASSO y regresión RIDGE. Estos modelos no son compatibles con valores faltantes, ni variables categóricas. Por lo tanto, lo mínimo absoluto que debemos hacer con nuestros datos es eliminar muestras con faltantes y variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_preprocessing(X, y):\n",
    "    print('Tamaño original:{}'.format(X.shape))\n",
    "    categorical_columns = X.dtypes[X.dtypes == 'category'].index.values\n",
    "    # Eliminamos variables categoricas\n",
    "    X=X.drop(columns=categorical_columns)\n",
    "    print('Eliminadas: {}'.format(categorical_columns))\n",
    "    # Eliminamos valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('Nuevo tamaño:{}'.format(X.shape))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a810e2",
   "metadata": {},
   "source": [
    "Aplicaremos por separado nuestro preprocesamiento a nuestras particiones de entrenamiento y prueba para evitar generar sesgos en nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aed16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = minimum_preprocessing(X_train,y_train)\n",
    "X_test, y_test = minimum_preprocessing(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12252ec",
   "metadata": {},
   "source": [
    "### Regresión lineal\n",
    "\n",
    "Pequeño recordatorio de como funciona la regresión lineal: \n",
    "\n",
    "Modelamos nuestra función de regresión como\n",
    "\n",
    " $y = f(x) + \\epsilon = w^\\top x + \\epsilon$\n",
    " \n",
    " dónde:\n",
    " * $y$ es nuestro objetivo.\n",
    " * $w$ son los pesos que calcularemos.\n",
    " * $x$ son nuestras muestras.\n",
    " * $\\epsilon$ es el ruido de las muestras.\n",
    "\n",
    "Si asumimos que el ruido es gaussiano, resolver este problema equivale a minimizar el error cuadrático medio de esta función.\n",
    "\n",
    "$\\min_w || y-Xw ||^2$\n",
    "\n",
    "Veremos dos implementaciones diferentes de regresión lineal. La de statsmodels y la de scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869c10a",
   "metadata": {},
   "source": [
    "#### Scikit-learn linear regression\n",
    "\n",
    "Los modelos scikit-klearn son realmente fáciles de usar. Todos están implementados en clases con la misma estructura, por lo que al conocer uno, se conocen todos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893777d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo LinearRegression \n",
    "lr = LinearRegression();\n",
    "\n",
    "# Ajustamos con los datos de entrenamiento con el método fit\n",
    "lr.fit(X_train,y_train);\n",
    "\n",
    "# Predecimos con el método predict \n",
    "y_pred = lr.predict(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cac369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "# Podemos acceder a información del modelo, como los pesos.\n",
    "print('Coeficientes: \\n', weights[:10])\n",
    "print('Interceptor: \\n', intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4add2",
   "metadata": {},
   "source": [
    "\n",
    "#### Statsmodels linear regression\n",
    "*La regresión lineal de Statsmodels* es un poco más difícil de usar pero genera una gran cantidad de datos estadísticos que pueden ser útiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c3111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression se llama ordinary least squares (OLS) en statsmodels\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990719b",
   "metadata": {},
   "source": [
    "Interpretando esta salida:\n",
    "\n",
    "Cada muestra individual será una matriz con la siguiente estructura:\n",
    "\n",
    "$x=(1, adult\\_mortality, infant\\_deaths,\\dots, schooling)^T$\n",
    "\n",
    "Los pesos del modelo después del entrenamiento son:\n",
    "\n",
    "$w=(53.8131, -0.017, 0.1059, \\dots,0.9182)^T$\n",
    "\n",
    "Y el modelo:\n",
    "\n",
    "$y(x; w) = w^T x = 53.8131 - 0.017*adult\\_mortality + 0.1059*infant\\_deaths + \\dots + 0.9182*schooling$\n",
    "\n",
    "Además de los pesos, statsmodels devuelve el intervalo de confianza del 95 % de estos pesos ([0,025 0,975]), el error estándar de los pesos (std err) y el valor p (P>|z|). Si el valor de p es menor a un umbral (generalmente 0.05), podemos decir que la variable es relevante para predecir el objetivo.\n",
    "\n",
    "Los residuos (la diferencia entre el valor objetivo real y el valor objetivo previsto) son:\n",
    "\n",
    " $(t_n - y(x_n; w)), n = 1,\\dots N$\n",
    "\n",
    "Si representamos los residuos de los datos de entrenamiento obtenemos la siguiente distribución:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb448894",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlim([-15,15])\n",
    "sns.distplot(result.resid,bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf627f",
   "metadata": {},
   "source": [
    "Esperamos que este gráfico parezca gaussiano, ya que es nuestra suposición inicial (error gaussiano). Por esta razón, esta gráfica es un indicador directo de la validez del modelo.\n",
    "\n",
    "Otra gráfica que podemos usar para validar nuestro modelo es un QQ-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "stats.probplot(result.resid, plot=plt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387de7b",
   "metadata": {},
   "source": [
    "Podemos obtener un gráfico de los residuos del entrenamiento y el test con el _qqplot_ o el _histograma_ con la librería `yellowbrick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d041f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import residuals_plot\n",
    "plt.figure(figsize=(12,8));\n",
    "viz = residuals_plot(lr, X_train, y_train, X_test, y_test, is_fitted=True, qqplot=True, hist=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877145c6",
   "metadata": {},
   "source": [
    "También podemos representar las predicciones respecto a los valores reales y ver cuanto se desvían de la predicción ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb855420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import prediction_error\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "visualizer = prediction_error(lr, X_test, y_test, is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc056c7f",
   "metadata": {},
   "source": [
    "## SECCIÓN 3: Metricas\n",
    "\n",
    "Hay métricas alternativas que podemos usar para medir el rendimiento de un modelo de regresión.\n",
    "Repasaremos las más comunes sobre las predicciones de datos de entrenamiento.\n",
    "\n",
    "**Mean Squared Error (MSE)** \n",
    "\n",
    "El mejor resultado posible sería un MSE de 0, lo que significaría una predicción perfecta.\n",
    "\n",
    "$MSE(t,y) = \\frac{1}{N} \\sum_{i=1}^N (t - y(x;w))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "\n",
    "# usando statsmodel\n",
    "prediction = result.predict(sm.add_constant(X_train))\n",
    "mean_square_error = np.sum((y_train - prediction)**2)/N\n",
    "\n",
    "# También se puede calcular con su implementacion en scikit-learn\n",
    "mean_square_error_sk = mean_squared_error(y_train, prediction)\n",
    "\n",
    "mean_square_error, mean_square_error_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845973a6",
   "metadata": {},
   "source": [
    "Este número depende de la magnitud de la variable objetivo, por lo que no podemos saber si es bueno o malo directamente. Es una muy buena práctica normalizarlo dividiendo por la varianza no sesgada de la muestra de la variable objetivo. De esta manera obtenemos el\n",
    "\n",
    "**Normalized Mean Squared Error**\n",
    "\n",
    "Nuevamente, el mejor resultado posible sería 0, por la misma razón.\n",
    "\n",
    "$norm\\_MSE(t,y) = \\frac {MSE(t,y)}{\\sigma^2(t)} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mse = np.sum((y_train - prediction)**2)/((N)*np.var(y_train))\n",
    "\n",
    "# Se puede usar la implementacion de R^2 de para calcular este valor\n",
    "norm_mse_sk = 1-r2_score(y_train,prediction)\n",
    "\n",
    "norm_mse, norm_mse_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7097613",
   "metadata": {},
   "source": [
    "Si dividimos el error cuadrático medio por la varianza de los objetivos t,\n",
    " obtenemos la proporción de la variabilidad del objetivo que NO es explicada por el modelo\n",
    "\n",
    " Un modelo con 'norm.mse' igual a 1 es tan bueno como el mejor modelo constante\n",
    " (es decir, el modelo que siempre da como respuesta el promedio del objetivo)\n",
    "\n",
    " los modelos con 'norm.mse' por encima de 0.5 son regulares, mas alla de 0.7 empiezan a ser bastante malos\n",
    "\n",
    " los modelos con 'norm.mse' por debajo de 0.2 son bastante buenos\n",
    "\n",
    "\n",
    "**R-squared (R^2)**\n",
    "\n",
    "El R^2 (generalmente utilizado por los estadísticos) se obtiene restando esta cantidad de uno; es decir, la proporción de la variabilidad objetivo que explica el modelo; en este caso alcanza ~80%\n",
    "\n",
    "Esta métrica suele mostrarse entre 0 y 1 o en porcentaje, pero hay que tener en cuenta que no esta limitada por abajo, una regresión puede ser arbitrariamente mala (valores negativos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_squared = (1 - norm_mse)\n",
    "\n",
    "# También se puede usar la implementacion de scikit-learn\n",
    "R_squared_sk = r2_score(y_train,prediction) \n",
    "\n",
    "R_squared, R_squared_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d9796",
   "metadata": {},
   "source": [
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "El mejor resultado posible también sería un MAE de 0, lo que significaría una predicción perfecta.\n",
    "\n",
    "$MAE(t,y) = \\frac{1}{N} \\sum_{i=1}^N |t - y(x;w)|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae =  np.sum(np.abs(y_train - prediction))/N\n",
    "\n",
    "# Se puede usar la implementacion de MAE de para calcular este valor\n",
    "mae_sk = mean_absolute_error(y_train,prediction)\n",
    "\n",
    "mae, mae_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f87eb",
   "metadata": {},
   "source": [
    "Hemos visto aquí que el modelo tiene buenos resultados con los datos de entrenamiento, pero eso no significa que nuestro modelo sea un buen predictor.\n",
    "Para tener una valoración numérica de su capacidad predictiva tenemos varias opciones:\n",
    "* Obtenga nuevos datos (¡no es posible aquí!)\n",
    "* Utilizar LOOCV.\n",
    "* Predecir sobre una partición de validación específica y calcular las medidas pertinentes.\n",
    "* Utilizar la validación cruzada.\n",
    "\n",
    "No hemos guardado una partición específica para obtener métricas de validación y tenemos demasiadas muestras (1123 en proceso) para hacer LOOCV rápido. Por esta razón haremos validación cruzada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864b509e",
   "metadata": {},
   "source": [
    "## SECCIÓN 4: Validación cruzada (Cross Validation)\n",
    "\n",
    "Necesitamos saber qué tan bueno es nuestro modelo. No podemos usar el conjunto de datos de entrenamiento para esto porque podría dar resultados artificialmente buenos. No podemos usar la partición de prueba porque necesitaremos comparar estos resultados con los obtenidos en otros modelos. Queremos usar el conjunto de prueba solo al final, para que pueda simular la ejecución del modelo con datos nuevos. De esta manera podemos obtener un error de generalización lo más cercano posible al error que obtendríamos usando el modelo con datos completamente nuevos.\n",
    "\n",
    "Como no podemos usar ni el entrenamiento ni el conjunto de prueba para evaluar el modelo, usaremos **Validación cruzada** para calcular nuestras métricas, usaremos estas métricas comparar modelos y tomar cualquier decisión de diseño.\n",
    "\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bc29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics = pd.DataFrame(columns=['MSE', 'norm_MSE', 'R2'])\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "i=1\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print('Split {}: \\n\\tTest Folds: [{}] \\n\\tTrain Folds {}'.format(i, i, [j for j in range(1,6) if j != i]));\n",
    "    \n",
    "    x_train_fold = X_train.values[train_index]\n",
    "    y_train_fold = y_train.values[train_index]\n",
    "    x_test_fold = X_train.values[test_index,:]\n",
    "    y_test_fold = y_train.values[test_index]\n",
    "    \n",
    "    lr = LinearRegression().fit(x_train_fold,y_train_fold)\n",
    "    y_pred_fold = lr.predict(x_test_fold)\n",
    "    fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "    fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "    fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "    print(f'\\tMSE: {fold_mse:3.3f} NMSE: {fold_nmse:3.3f} R2: {fold_r2:3.3f}')\n",
    "\n",
    "    cross_val_metrics.loc[f'Fold {i}', :] = [fold_mse,fold_nmse, fold_r2]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d622e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_metrics.loc['Mean',:] = cross_val_metrics.mean()\n",
    "cross_val_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb78c1e",
   "metadata": {},
   "source": [
    "Usaremos la media de las particiones como nuestra métrica. También podemos hacer esto usando el método sklearn `cros_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train);\n",
    "folds_r2 = cross_val_score(lr, X_train,y_train, cv=5, scoring='r2')\n",
    "lr_r2 = np.mean(folds_r2) \n",
    "folds_r2, lr_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac732883",
   "metadata": {},
   "source": [
    "## SECCIÓN 5: Regresión lineal regularizada: Ridge and LASSO\n",
    "\n",
    "Ahora que tenemos una forma de evaluar el rendimiento de nuestro modelo, veamos si mejora agregando regularización. \n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Esta vez vamos a minimizar la siguiente función:\n",
    "\n",
    "$\\min_w (|| y - Xw ||^2 + \\lambda \\cdot ||w||^2_2)$\n",
    "\n",
    "El último término penaliza que los pesos sean demasiado grandes (en magnitud).\n",
    "El hiperparámetro $\\lambda$ controlará cuánto los estamos penalizando.\n",
    "\n",
    "Lambda no se calcula sobre el proceso de entrenamiento como los pesos, es un *hiperparámetro*.\n",
    "Entonces ahora la pregunta es: ¿Cómo podemos encontrar la mejor $\\lambda$ para nuestro conjunto de datos?\n",
    "\n",
    "Hemos dicho en la sección anterior que podemos usar métricas de validación cruzada para comparar el rendimiento predictivo de diferentes modelos. Podemos hacer lo mismo para comparar el mismo modelo con diferentes hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363227ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cross_val_metrics = pd.DataFrame(columns=['mean MSE', 'mean norm_MSE', 'mean R2'])\n",
    "lambdas = [1e-4,1e-3,1e-2,0.1, 0.5,1,5,10,50,100]\n",
    "# Calculamos las metricas de validación cruzada para cada lambda\n",
    "for lambda_val in lambdas:\n",
    "    kf = KFold(n_splits=5)\n",
    "    i=1\n",
    "    cv_mse = []\n",
    "    cv_nmse = []\n",
    "    cv_r2 = []\n",
    "    # Calculamos la metrica para cada particion y hacemos la media\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        x_train_fold = X_train.values[train_index]\n",
    "        y_train_fold = y_train.values[train_index]\n",
    "        x_test_fold = X_train.values[test_index,:]\n",
    "        y_test_fold = y_train.values[test_index]\n",
    "\n",
    "        lr = Ridge(alpha=lambda_val).fit(x_train_fold,y_train_fold)\n",
    "        y_pred_fold = lr.predict(x_test_fold)\n",
    "        fold_mse =mean_squared_error(y_test_fold, y_pred_fold)\n",
    "        fold_nmse =  1-r2_score(y_test_fold, y_pred_fold)\n",
    "        fold_r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "        cv_mse.append(fold_mse)\n",
    "        cv_nmse.append(fold_nmse)\n",
    "        cv_r2.append(fold_r2)\n",
    "    ridge_cross_val_metrics.loc[f'Lambda={lambda_val}',:] = [np.mean(cv_mse),np.mean(cv_nmse),np.mean(cv_r2)]\n",
    "    \n",
    "ridge_cross_val_metrics.sort_values(by='mean R2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f194309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858a56",
   "metadata": {},
   "source": [
    "Otra manera es usar la implementacion de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8448b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv =RidgeCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "\n",
    "print(f'Best lambda: {ridge_cv.alpha_} R2 score: {ridge_cv.best_score_:3.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58b5d2",
   "metadata": {},
   "source": [
    "Podemos obtener una visualización usando el método AlphaSelection de `yellowbrick`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c272e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "vis = AlphaSelection(RidgeCV(alphas=lambdas));\n",
    "vis.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b29ed8",
   "metadata": {},
   "source": [
    "Ridge Regression no parece mejorar los resultados de la regresión lineal. Comprobemos si LASSO funciona mejor.\n",
    "\n",
    "### Regresión LASSO\n",
    "\n",
    "Esta vez penalizamos los pesos usando su norma L1.\n",
    "\n",
    "\n",
    "$\\min_w (|| y - Xw ||^2 + \\lambda * |w|)$\n",
    "\n",
    "Usaremos el método CV de scikit-learn para calcular la mejor $\\lambda$ directamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv =LassoCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "\n",
    "lasso_r2 =  np.mean(cross_val_score(lasso_cv, X_train,y_train))\n",
    "\n",
    "print('Best lambda:', lasso_cv.alpha_, 'R2 score:',lasso_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "vis = AlphaSelection(LassoCV(alphas=lambdas));\n",
    "vis.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc10c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results = pd.DataFrame({'lr':lr_r2, 'ridge_cv':ridge_cv.best_score_, 'lasso_cv':lasso_r2},index=['CV R2'])\n",
    "\n",
    "r2_results.loc['Train R2', :] =[r2_score(y_train,lr.predict(X_train)),\n",
    "                                r2_score(y_train,ridge_cv.predict(X_train)),\n",
    "                                r2_score(y_train,lasso_cv.predict(X_train))]\n",
    "r2_results.loc['lambda','lr']=0\n",
    "r2_results.loc['lambda','ridge_cv']=ridge_cv.alpha_\n",
    "r2_results.loc['lambda','lasso_cv']=lasso_cv.alpha_\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3d13c",
   "metadata": {},
   "source": [
    "## SECCIÓN 6: Entender los modelos es importante &#x261d;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ab02b",
   "metadata": {},
   "source": [
    "Tampoco podemos ver una gran mejora con LASSO.\n",
    "\n",
    "Entonces, ¿por qué la regularización no funciona cuando se supone que debe dar mejores modelos?\n",
    "\n",
    "Comprobemos los pesos de nuestros tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6faa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = pd.DataFrame({'lr':lr.coef_, 'ridge_cv':ridge_cv.coef_, 'lasso_cv':lasso_cv.coef_},index=X_train.columns)\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351059c",
   "metadata": {},
   "source": [
    "Visualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2775abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,  ax = plt.subplots( figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['lr'],:].abs(),annot=True, linewidths=.5,ax=ax,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['ridge_cv'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=False);\n",
    "\n",
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(weights.T.loc[['ridge_cv'],:].abs(),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f50c9f",
   "metadata": {},
   "source": [
    "Podemos ver algunos patrones extraños en nuestros pesos, en los tres modelos podemos ver una amplia gama de valores. Tanto LASSO como Ridge tienen casi el mismo peso.\n",
    "\n",
    "Si comparamos los pesos con los valores medios de nuestras variables, podemos ver que la regresión lineal está tratando de equilibrar los rangos de las variables. Probablemente por eso nuestros modelos regularizados no funcionan tan bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(X_train.mean().to_frame().T.rename(index={0:'Mean'}),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c2771",
   "metadata": {},
   "source": [
    "Vamos a arreglar esto escalando nuestros datos. De esta forma, todas las variables tendrán el mismo rango y aprovecharemos mejor nuestros modelos.\n",
    "\n",
    "**Tened en cuenta que la forma de hacer el procesamiento previo para los datos del test se obtiene del que hemos hecho a los datos de entrenamiento. Esencialmente, esto es para evitar cualquier tipo de sesgo entre entrenamiento y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_preprocessing(X, y, scaler=None):\n",
    "    print('Tamaño Original:{}'.format(X.shape))\n",
    "    categorical_columns = X.dtypes[X.dtypes == 'category'].index.values\n",
    "    \n",
    "    # Escalamos las variables numericas\n",
    "    numerical_columns = [c for c in X.columns if c not in categorical_columns]\n",
    "    if scaler is None: \n",
    "        # Generamos el scaler cuando los datos son los de entrenamiento\n",
    "        scaler = MinMaxScaler()\n",
    "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "    else: \n",
    "        X[numerical_columns] = scaler.transform(X[numerical_columns])\n",
    "    \n",
    "    # Eliminamos las variables categoricas\n",
    "    X=X.drop(columns=categorical_columns)\n",
    "    print('Eliminadas: {}'.format(categorical_columns))\n",
    "    # Eliminamos los valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y, scaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, y_train, scaler = scaling_preprocessing(X_train,y_train)\n",
    "X_test, y_test, _ = scaling_preprocessing(X_test,y_test,scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e0347",
   "metadata": {},
   "source": [
    "Ahora nuestras variables tienen rangos más razonables. Veamos cómo afecta esto a los pesos y el rendimiento de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730b017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(X_train.mean().to_frame().T.rename(index={0:'Mean'}),annot=True, linewidths=.5,cbar=False,xticklabels=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48951aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scaled = LinearRegression().fit(X_train,y_train)\n",
    "r2_lr_scaled = np.mean(cross_val_score(lr_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "ridge_cv_scaled =RidgeCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "r2_ridge_scaled = np.mean(cross_val_score(ridge_cv_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "\n",
    "lasso_cv_scaled =LassoCV(alphas=lambdas,cv=5).fit(X_train,y_train)\n",
    "r2_lasso_scaled = np.mean(cross_val_score(ridge_cv_scaled, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "weights = pd.DataFrame({'lr scaled':lr_scaled.coef_, 'ridge_cv scaled':ridge_cv_scaled.coef_, 'lasso_cv scaled':lasso_cv_scaled.coef_},index=X_train.columns)\n",
    "weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d830a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results = pd.DataFrame({'lr':r2_lr_scaled, 'ridge_cv':r2_ridge_scaled, 'lasso_cv':r2_lasso_scaled,},index=['CV R2'])\n",
    "\n",
    "r2_results.loc['Train R2', :] =[r2_score(y_train,lr_scaled.predict(X_train)),\n",
    "                                r2_score(y_train,ridge_cv_scaled.predict(X_train)),\n",
    "                                r2_score(y_train,lasso_cv_scaled.predict(X_train))]\n",
    "r2_results.loc['lambda','lr']=0\n",
    "r2_results.loc['lambda','ridge_cv']=ridge_cv_scaled.alpha_\n",
    "r2_results.loc['lambda','lasso_cv']=lasso_cv_scaled.alpha_\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34f70a",
   "metadata": {},
   "source": [
    "Los resultados no han mejorado mucho. Tal vez la inclusión de variables categóricas ayude.\n",
    "\n",
    "Tenemos dos variables categóricas. País y estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4018a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_preprocessing(X, y,scaler=None):\n",
    "    print('Original shape:{}'.format(X.shape))\n",
    "    categorical_columns =X.dtypes[X.dtypes == 'category'].index.values\n",
    "    numerical_columns = [c for c in X.columns if c not in categorical_columns]\n",
    "    \n",
    "    # Escalamos las variables numericas\n",
    "    if scaler is None: \n",
    "        # Generamos el scaler cuando los datos son los de entrenamiento\n",
    "        scaler = MinMaxScaler()\n",
    "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "    else: \n",
    "        X[numerical_columns] = scaler.transform(X[numerical_columns])\n",
    "    \n",
    "    # Aplicamos un one-hot encoding a las variables categoricas\n",
    "    for column in categorical_columns:\n",
    "        X_one_hot = pd.get_dummies(X[column], prefix=column)\n",
    "        X = X.merge(X_one_hot,left_index=True,right_index=True)\n",
    "        X = X.drop(columns=[column])\n",
    "    \n",
    "    # Eliminamos los valores perdidos\n",
    "    X=X.dropna()\n",
    "    y=y[X.index]\n",
    "    print('New shape:{}'.format(X.shape))\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, y_train, scaler = categorical_preprocessing(X_train,y_train)\n",
    "X_test, y_test, _ = categorical_preprocessing(X_test,y_test,scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2eaff7",
   "metadata": {},
   "source": [
    "Si usamos este nuevo preprocesamiento obtenemos muy buenos resultados en el conjunto de entrenamiento pero muy malos resultados en la validación cruzada.\n",
    "\n",
    "Esto significa que nuestro modelo no podrá generalizarse si tratamos de usarlo en datos nuevos.\n",
    "\n",
    "¿Cómo puede ser que teniendo más información nuestro modelo esté funcionando peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ea148",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_one_hot = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "r2_lr_one_hot_train = lr_one_hot.score(X_train,y_train)\n",
    "r2_lr_one_hot_cv = np.mean(cross_val_score(lr_one_hot, X_train,y_train, cv=5, scoring='r2'))\n",
    "\n",
    "print('Train R2 score: {}\\nCross-Validation R2 score: {}'.format(r2_lr_one_hot_train, r2_lr_one_hot_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf1a4ea",
   "metadata": {},
   "source": [
    "Tenemos dos problemas con nuestro modelo:\n",
    "1. Está **sobreajustando** los datos de entrenamiento. Entonces, cuando recibe nuevos datos que no se han utilizado en el entrenamiento, no puede predecir.\n",
    "2. Esto podría deberse a la **maldición de la dimensionalidad**. Tenemos 214 variables para 1123 muestras, que no es una gran proporción.\n",
    "\n",
    "También podemos ver en los pesos de nuestro modelo que algo falla, ya que hay diferencias entre los rangos de peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d499d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,1));\n",
    "sns.heatmap(pd.DataFrame({'lr overfitted':lr_one_hot.coef_}).T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea02bbbf",
   "metadata": {},
   "source": [
    "Finalmente, si comprobamos cómo se ven nuestros datos, veremos que tenemos una matriz muy dispersa. Entonces, además de todos nuestros problemas, estamos tratando de usar SVD en una matriz dispersa, lo cual no es lo ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10394126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8));\n",
    "sns.heatmap(X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facccb18",
   "metadata": {},
   "source": [
    "Para corregir el sobreajuste, podemos eliminar esta variable o aplicar la regularización. Veamos cómo se comportan nuestros modelos regularizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faee252",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_one_hot = RidgeCV(alphas=lambdas, cv=5).fit(X_train, y_train)\n",
    "\n",
    "r2_ridge_one_hot_train = ridge_cv_one_hot.score(X_train,y_train)\n",
    "r2_ridge_one_hot_cv = np.mean(cross_val_score(ridge_cv_one_hot, X_train, y_train, cv=5, scoring='r2'))\n",
    "\n",
    "lasso_cv_one_hot = LassoCV(alphas=lambdas, cv=5).fit(X_train, y_train)\n",
    "\n",
    "r2_lasso_one_hot_train = ridge_cv_one_hot.score(X_train,y_train)\n",
    "r2_lasso_one_hot_cv = np.mean(cross_val_score(lasso_cv_one_hot, X_train, y_train, cv=5, scoring='r2'))\n",
    "\n",
    "weights = pd.DataFrame(\n",
    "    {\n",
    "        'lr_one_hot': lr_one_hot.coef_,\n",
    "        'ridge_cv_one_hot': ridge_cv_one_hot.coef_,\n",
    "        'lasso_cv_one_hot': lasso_cv_one_hot.coef_\n",
    "    },\n",
    "    index=X_train.columns)\n",
    "\n",
    "for column in weights.columns:\n",
    "    fig= plt.figure(figsize=(20,1))\n",
    "    ax=sns.heatmap(weights[[column]].T, cmap=\"seismic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f31eb",
   "metadata": {},
   "source": [
    "Obtenemos menores pesos en nuestros modelos regularizados. ¿Afectará esto al rendimiento de nuestros modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_results.loc[:, 'lr_one_hot'] =[r2_lr_one_hot_cv, r2_lr_one_hot_train, 0]\n",
    "r2_results.loc[:, 'ridge_cv_one_hot'] =[r2_ridge_one_hot_cv, r2_ridge_one_hot_train, ridge_cv_one_hot.alpha_]\n",
    "r2_results.loc[:, 'lasso_cv_one_hot'] =[r2_lasso_one_hot_cv, r2_lasso_one_hot_train, lasso_cv_one_hot.alpha_]\n",
    "r2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437b602",
   "metadata": {},
   "source": [
    "Podemos ver en nuestras métricas de cv que la regularización mejora el rendimiento **mucho**. De esta forma, el modelo puede aprovechar los datos adicionales que le proporcionamos y controlar eficazmente el sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199207a3",
   "metadata": {},
   "source": [
    "## SECCIÓN 7: Selección del modelo\n",
    "\n",
    "Ahora usamos el R^2  para elegir el mejor modelo, obtendremos para el conjunto de test esta medida. Según nuestras métricas de validación, el mejor modelo es ridge_cv con una lambda de 0,001 utilizada con el conjunto de datos estandarizados con variables categóricas.\n",
    "\n",
    "Ahora que hemos tomado todas las decisiones relacionadas con nuestro modelo y el preprocesamiento de datos. Usamos el conjunto de prueba para ver cómo se generaliza el modelo. Se supone que este paso simula cómo funciona el modelo con datos *completamente nuevos*, es decir, datos que nunca antes había visto.\n",
    "\n",
    "**Normalmente, antes de probar el \"método ganador\" lo voleríamos a ajustar con todos los datos de entrenamiento; el método RidgeCV hace esto de forma predeterminada para nosotros, por lo que no es necesario que lo hagamos aquí.**\n",
    "\n",
    "Es importante usar el conjunto de test solo para dar el rendimiento final, de lo contrario corremos el riesgo de dar un resultado demasiado optimista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tes_predicted = ridge_cv_one_hot.predict(X_test)\n",
    "r2_ridge = ridge_cv_one_hot.score(X_test,y_test)\n",
    "\n",
    "print('Mean sqared error with test data: {}'.format(mean_squared_error(y_test,y_tes_predicted)))\n",
    "print('R2 score with test data: {}'.format(r2_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "visualizer = prediction_error(ridge_cv_one_hot, X_test, y_test, is_fitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "viz = residuals_plot(ridge_cv_one_hot, X_train, y_train, X_test, y_test, is_fitted=True, qqplot=True, hist=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Running time {timedelta(seconds=(time() - init_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
