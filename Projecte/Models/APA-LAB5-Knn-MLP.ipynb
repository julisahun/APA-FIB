{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1f12f; Javier Bejar - APA/GEI/FIB/UPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to upgrade packages\n",
    "# !pip3 install pandas --user --upgrade --quiet\n",
    "# !pip3 install numpy --user --upgrade --quiet\n",
    "# !pip3 install scipy --user --upgrade --quiet\n",
    "# !pip3 install statsmodels --user --upgrade --quiet\n",
    "# !pip3 install seaborn --user --upgrade --quiet\n",
    "# !pip3 install matplotlib --user --upgrade --quiet\n",
    "# !pip3 install scikit-learn --user --upgrade \n",
    "# !pip install scikit-optimize --user --quiet\n",
    "!pip install apafib --upgrade --user --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "show_html = lambda html: display(HTML(html))\n",
    "\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "init_time = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APA - Laboratorio - Sesión 5\n",
    "## K-nearest neighbours - Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import set_config\n",
    "\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay,\\\n",
    "                  classification_report,  RocCurveDisplay, PrecisionRecallDisplay,\\\n",
    "                    accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split, cross_val_score, TimeSeriesSplit\n",
    "\n",
    "from yellowbrick.classifier.rocauc import roc_auc\n",
    "from yellowbrick.target.feature_correlation import feature_correlation\n",
    "from yellowbrick.classifier import precision_recall_curve\n",
    "\n",
    "from apafib import load_electric_devices, load_energy\n",
    "\n",
    "import warnings\n",
    "\n",
    "set_config(display='text')\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# sns.set()\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(clf, X_test, y_test, nclf, df):\n",
    "    df.loc[nclf,'test acc'] = accuracy_score(y_test, clf.predict(X_test))\n",
    "    df.loc[nclf,'precision score (W)'] = precision_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    df.loc[nclf,'recall score (W)'] = recall_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    df.loc[nclf,'f1 score (W)'] = f1_score(y_test, clf.predict(X_test), average='weighted')\n",
    "    return df\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "niter = 15\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seccion 1: Electric Devices Consumption - Clasificación\n",
    "\n",
    "Este conjunto de datos corresponde al patron de consumo de un dia (cada 15 minutos) de un conjunto de aparatos electrónicos comunes (7) en una casa. El objetivo es clasificar el patrón de consumo en el aparato correspondiente.\n",
    "\n",
    "Este conjunto de datos solo tiene datos continuos, esto es más adecuado para estos dos modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_electric_devices()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 7 clases con cierto imbalance entre ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = [str(v) for v in sorted(data['Class'].unique())]\n",
    "cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar si tenemos datos perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.columns:\n",
    "    if data[c].isna().sum()>0:\n",
    "        print(c, data[c].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos la clase de los atributos y obtenemos el conjunto de entrenamiento y test de manera estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.iloc[:,1:]\n",
    "y= data.loc[:,'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es poco práctico el visualizar 96 atributos, podríamos comprobar las caracterísitcas de los atributos por ejemplo calculando test estadísticos sobre su distribución si queremos usar algún modelo que asuma alguna distribución a priori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos no obstante esperar cierta correlación entre instantes consecutivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X_train.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr, mask=mask, cmap='seismic',  center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Para poder ver si hay alguna relación entre las variables y las clases podemos usar métodos de reducción de dimensionalidad, aplicaremos PCA en este caso. Primero estandarizaremos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscaler = StandardScaler()\n",
    "X_train_sd = sscaler.fit_transform(X_train)\n",
    "X_test_sd = sscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(X_train_sd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6));\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),pca.explained_variance_ratio_ ,alpha=0.8,marker='.',label=\"Variancia Explicada\");\n",
    "y_label = plt.ylabel('Variancia explicada');\n",
    "x_label = plt.xlabel('Componentes');\n",
    "plt.plot(range(1,len(pca.explained_variance_ratio_ )+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         c='red',marker='.',\n",
    "         label=\"Variancia explicada acumulativa\");\n",
    "plt.legend();\n",
    "plt.title('Porcentaje de variancia explicada por componente');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la variancia de los datos esta distribuida por todos los componentes asi que una visualizacion en dos dimensiones nos va a dar una visión limitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train_sd)\n",
    "X_test_pca = pca.transform(X_test_sd)\n",
    "plt.figure(figsize=(8,8));\n",
    "sns.scatterplot(x=X_train_pca[:,0], y=X_train_pca[:,1], hue=y_train, palette='tab10');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aun así, podemos ver que hay cierta separabilidad entre las clases, aunque es dificil decir si todas son separables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nearest neighbours\n",
    "\n",
    "K-nn funciona a partir de la recuperación de los vecinos más cercanos a partir de su distancia, por lo que es importate que todos los atributos se encuenten en la misma escala asi que los normalizamos utilizando el MinMax scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos explorar el rango de hperparámetos de K-nn, basicamente cuantos vecinos usamos para hacer la predicción, que distancias usamos para recuperarlos, como combinamos las distancias y cual es la resolución del indice que nos permite recuperar los vecinos (kd-tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn =  KNeighborsClassifier()\n",
    "print(np.mean(cross_val_score(knn,X_train_s,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_neighbors':[1, 3, 5, 7, 11, 15], \n",
    "          'weights':['distance', 'uniform'], \n",
    "          'leaf_size':[1, 5, 10, 20, 30],\n",
    "          'metric': ['l2', 'l1', 'cosine']}\n",
    "\n",
    "knn_gs =  GridSearchCV(knn,param,cv=cv, n_jobs=-1)\n",
    "knn_gs.fit(X_train_s, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que hay todo un conjuto de hiperparámetos que dan el mismo resutado (al menos al tercer decimal). Los resultados se ordenan lexicograficamente, por defecto la mejor solucion tendra un indice con un ejemplo por hoja. En un caso práctico, a igualdad de resultados, un indice con más ejemplos por hoja debería ser más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(knn_gs.predict(X_test_s), y_test,target_names=cls))\n",
    "results_df = save_results(knn_gs, X_test_s, y_test, 'KNN', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el acierto en el test es consistente con la validación cruzada. No todas las clases tienen los mismos resultados, las ultimas dos son las que tienen peor resultado. Esto puede deberse básicamente a que no tienen una gran diferencia con el resto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(knn_gs, X_test_s,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos ver que hay clases que tienen bastante confusión con las clases que peor resultado tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(knn_gs, X_train_s, y_train, X_test_s, y_test, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos la ROC multiclase es más dificil de interpretar, pero podemos ver que hay una clase fácilmente separable del resto, el resto nos daran un relativamente alto porcentaje de falsos positivos (~20%) \n",
    "\n",
    "Podemos usar permutation importance para ver que atributos parecen más importantes para la clasificación. En este caso tenemos 96 atributos asi que reduciremos la muestra con la que se calcula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = choice(X_test.shape[0], size=1000, replace=False)\n",
    "pi = permutation_importance(knn_gs,X_test_s[c], y_test.to_numpy()[c], n_jobs=-1, random_state=0)\n",
    "var_imp = pd.DataFrame({'importance': pi.importances_mean}, index=data.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la importanci se distribuye entre bastantes horas, pero las 7:45 horas parece ser bastante significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp.sort_values(by='importance').plot.barh(figsize=(10,20), legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos, K-nn tiene problemas cuando la dimensionalidad crece, en este caso podemos usar los componentes de PCA para reducir estas dimensiones y comprobar si podemos reducir el tamaño sin comprometer la calidad del resultado. \n",
    "\n",
    "En un caso práctico esto puede ayudarnos a reducir la memoria necesaria para almacenar el modelos (tenemos que guardar los datos originales para poder predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = 40\n",
    "X_train_pca_s = scaler.fit_transform(X_train_pca[:,:nc])\n",
    "X_test_pca_s = scaler.transform(X_test_pca[:,:nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn =  KNeighborsClassifier()\n",
    "print(np.mean(cross_val_score(knn,X_train_pca_s,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_neighbors':[1, 3, 5, 7, 11, 15], \n",
    "          'weights':['distance', 'uniform'], \n",
    "          'leaf_size':[1, 5, 10, 20, 30],\n",
    "          'metric': ['l2', 'l1', 'cosine']}\n",
    "\n",
    "knn_gs =  GridSearchCV(knn,param,cv=cv, n_jobs=-1)\n",
    "knn_gs.fit(X_train_pca_s, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(knn_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que reducir alrededor de un 40% los atributos no reduce demasiado el error de crosvalidacion, habría que ver si compensa en la práctica o tiene sentido en la aplicación real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(knn_gs.predict(X_test_pca_s), y_test,target_names=cls))\n",
    "results_df = save_results(knn_gs, X_test_pca_s, y_test, 'KNN (PCA)', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error en el conjunto de test es coherente, pero hemos perdido calidad en la mejor clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(knn_gs, X_test_pca_s,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(knn_gs, X_train_pca_s, y_train, X_test_pca_s, y_test, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en la curva ROC que hemos simplificado el espacio de decisión, las curvas son discretas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "\n",
    "En el caso del MLP la forma en la que normalizamos los datos puede tener un impacto no solo en la calidad del resultado, sino tambien en la velocidad de convergencia. Usaremos el StandardScaler ya que converge más rápido, podeis cambiar vosotros la normalización para ver la diferencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdscaler = StandardScaler()\n",
    "\n",
    "X_train_sd = sdscaler.fit_transform(X_train)\n",
    "X_test_sd = sdscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El permitir early stopping reducira el tiempo de ajuste, es probable que el resultado sea algo peor a veces, pero reducimos la posibilidad de sobre ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=10000, early_stopping=True, n_iter_no_change=15, random_state=0)\n",
    "print(np.mean(cross_val_score(mlp,X_train_sd,y_train,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parametros por defecto dan un resultado parecido al Knn.\n",
    "\n",
    "Haremos primero una exploración en cuadrícula probando algunos valores para los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'hidden_layer_sizes':[10, 50, 100, 200], \n",
    "         'activation':['relu', 'logistic', 'identity'], \n",
    "         'learning_rate_init': [0.001, 0.01, 0.1]  }\n",
    "\n",
    "mlp =  MLPClassifier(max_iter=10000, early_stopping=True, n_iter_no_change=20,learning_rate='adaptive',random_state=0)\n",
    "mlp_gs =  GridSearchCV(mlp,param,cv=cv, n_jobs=-1, refit=True)\n",
    "mlp_gs.fit(X_train_sd, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(mlp_gs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un resultado algo peor. No podemos explorar completamente el espacio de hiperparámetros debido al coste de ajustar cada modelo.\n",
    "\n",
    "Una alternativa es utilizar una exploración aleatoria o dirigida de alguna manera pero no explorando todas las posibilidades. Un método que permite una buena exploración es la búsqueda bayesians. En esta vamos muestreando el espacio de hiperparámetros y obteniendo una función substituto que aproxima la calidad del resultado para todo el espacio de valores de manera que podemos ir escogiendo combinaciones dependiendo de la calidad  que  estime esta función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'hidden_layer_sizes':[10, 50, 100, 200, 300], \n",
    "'activation':['relu', 'identity', 'logistic'], \n",
    "'alpha':[0.0001, 0.001, 0.01],\n",
    "'momentum': [0.95, 0.90, 0.85, 0.8], \n",
    "'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "'n_iter_no_change':[10, 20, 40, 50], \n",
    "'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "mlp =  MLPClassifier(max_iter=10000,early_stopping=True,random_state=0)\n",
    "mlp_bs =  BayesSearchCV(mlp,param,\n",
    "                        n_iter=niter, \n",
    "                        cv=cv, n_jobs=-1, \n",
    "                        refit=True,random_state=0)\n",
    "mlp_bs.fit(X_train_sd, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(mlp_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que hay aleatoriedad en la búsqueda el resultado puede variar entre ejecuciones, pero podemos limitar el numero de ajustes del modelo y explorarlo más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(mlp_gs.predict(X_test_sd), y_test,target_names=cls))\n",
    "results_df = save_results(mlp_gs, X_test_sd, y_test, 'MLP', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error del test es coherente con el de validacion cruzada. El resultado es algo diferente, hemos mejorado en alguna de las clases peores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "ConfusionMatrixDisplay.from_estimator(mlp_bs, X_test_sd,y_test, display_labels=cls, ax=plt.subplot());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "roc_auc(mlp_bs, X_train_sd, y_train, X_test_sd, y_test, classes=cls);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de ese modelo es bastante parecido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = choice(X_test.shape[0], size=2000, replace=False)\n",
    "pi = permutation_importance(mlp_gs,X_test_sd[c], y_test.to_numpy()[c], n_jobs=-1, random_state=0)\n",
    "var_imp = pd.DataFrame({'importance': pi.importances_mean},\n",
    "                       index=data.columns[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La importancia de los atributos es diferente, pero el más importante es común entre los dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp.sort_values(by='importance').plot.barh(figsize=(10,20), legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by=['test acc'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2: Energy Data - Regresión\n",
    "\n",
    "Un problema que se puede resolver mediante regresión es la predicción de series de tiempo.\n",
    "\n",
    "La predicción de series temporales es un mundo en si mismo, pero también podemos usar modelos de aprendizaje para esta tarea. \n",
    "\n",
    "En este tipo de problemas queremos predecir valores de un momento en el tiempo a partir de los valores anteriores. En este caso debemos decidir cuantos instantes anteriores utilizamos y si utilizamos solo la variable objetivo o añadimos también otras variables que tengamos disponibles.\n",
    "\n",
    "En este caso usaremos un conjunto de datos parecido al de clasificación, queremos predecir el consumo de energia de los electrodomesticos de una casa. Tenemos muchos otros atributos, pero en este caso solo utilizaremos la variable objetivo. Podéis encontrar la documentación de este conjunto de datos aqui (https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = load_energy()\n",
    "\n",
    "niter = 15\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos la variable que queremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = data.loc[:,'Appliances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos un conjunto de entrenamiento (los 12000 primeros ejemplos) y de test (el resto).\n",
    "\n",
    "En este tipo de problemas no podemos hacer la partición del conjunto de datos como en el resto de problemas que hemos tratado. Fijaos que los datos no son iid. Ademas si partieramos aleatoriamente el conjunto de datos estariamos mezclando instantes en el tiempo, lo que nos interesa es poder ajustar el modelo con los datos del pasado y predecir los futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train, e_test =  energy.iloc[:12000], energy.iloc[12000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_train.shape, e_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar el conjunto de datos debemos generar una matriz de datos en la que tengamos ventanas de la serie.\n",
    "\n",
    "Para ello tenemos una función de numpy que tiene ese proposito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos un tamaño de ventana para hacer la matriz de datos. Usamos un tamaño w+1, asi tenemos la ventana anterior al dato a predecir en las primeras w posiciones y el dato a predecir en la última. \n",
    "\n",
    "La función que genera las ventanas nos retornará una matriz 3D, donde una de las dimensiones es una sola columna, la función `squeeze` nos elimina la columna redundante.\n",
    "\n",
    "Generamos la matriz de datos para el conjunto de entrenamiento y el de test.\n",
    "\n",
    "Normalizaremos primero los datos. Para Knn no deberia importar ya que todos los atributos se encuentran en el mismo rango, para MLP puede ayudar la convergencia ya que los datos estan en un rango de valores muy grande,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 4\n",
    "\n",
    "sdscaler = MinMaxScaler()\n",
    "\n",
    "e_train_s = sdscaler.fit_transform(e_train.to_numpy().reshape(-1, 1))\n",
    "e_test_s = sdscaler.transform(e_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "windows_train = sliding_window_view(e_train_s, w+1, axis=0).copy()\n",
    "X_train_w, y_train_w = windows_train.squeeze()[:,:-1], windows_train.squeeze()[:,-1]\n",
    "\n",
    "windows_test = sliding_window_view(e_test_s, w+1, axis=0).copy()\n",
    "X_test_w, y_test_w = windows_test.squeeze()[:,:-1], windows_test.squeeze()[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w.shape, X_test_w.shape, y_train_w.shape, y_test_w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K nearest neighbours\n",
    "\n",
    "El escalado de los datos en este caso sería innecesario ya que estamos utilizando la misma variable para generar todas las ventanas, asi que todas estarán un mismo rango. En todo caso normalizaríamos la variable antes de generar las ventanas.\n",
    "\n",
    "En este caso usamos Knn para regresión y exploramos el rango de hiper parámetros. \n",
    "\n",
    "Igual que no podemos mezclar el tiempo en los datos de entrenamiento y test, la validacion cruzada tampoco se puede realizar de la misma manera, nos hemos de asegurar de que la particion de entrenamiento siempre este en el pasado y la de validacion en el futuro y que no compartan ventanas de datos entre ellas. Esto nos lo permite TimeSeriesSplit. La medida que usamos para elegir el modelo es MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 5)\n",
    "knn =  KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_neighbors':[1, 3, 5, 7, 11, 15, 20, 25], \n",
    "         'weights':['distance', 'uniform'], \n",
    "         'leaf_size':[1, 5, 10, 15, 20, 25, 30],\n",
    "         'metric': ['l2', 'l1', 'cosine']}\n",
    "\n",
    "knn_bs = BayesSearchCV(knn,param,n_iter=niter, \n",
    "                        cv=TimeSeriesSplit(n_splits=cv, gap=w+1), \n",
    "                        scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                        n_jobs=-1, \n",
    "                        refit=True, random_state=0)         \n",
    "knn_bs.fit(X_train_w, y_train_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(knn_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error de MSE no esta en las unidades de los datos, calcular la raiz cuadrada del error nos pondrá en esas unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test_w,knn_bs.predict(X_test_w)), mean_absolute_error(y_test_w,knn_bs.predict(X_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error en el test es parecido al de validacion cruzada (incluso algo mejor).\n",
    "\n",
    "Podemos visualizar la predicción de los primeros datos del conjunto de test para ver como de cerca esta la prediccion del modelo de la realidad. No es un metodo de validacion, pero al menos nos permitirá ver si realmente estamos prediciendo algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(y_test_w[:500],'r');\n",
    "plt.plot(knn_bs.predict(X_test_w[:500,:]),'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la predicción sigue hasta cierto punto el principio de la serie del conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos el MLP para regresión.\n",
    "\n",
    "Exploramos los diferentes hiperparámetros del MLP, en este caso hacemos directamente una búsqueda bayesiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'hidden_layer_sizes':[100, 200, 300], \n",
    "         'activation':['relu',  'logistic'], \n",
    "         'alpha':[0.0001, 0.001, 0.01],\n",
    "         'momentum': [0.95, 0.90, 0.85], \n",
    "         'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "         'n_iter_no_change':[30, 40, 50], \n",
    "         'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "\n",
    "mlp =  MLPRegressor(max_iter=10000,early_stopping=True,random_state=0)\n",
    "mlp_bs = BayesSearchCV(mlp,param,n_iter=niter, \n",
    "                        cv=TimeSeriesSplit(n_splits=cv, gap=w+1), \n",
    "                        scoring=make_scorer(mean_squared_error, greater_is_better=False),\n",
    "                        n_jobs=-1, \n",
    "                        refit=True, random_state=0)    \n",
    "mlp_bs.fit(X_train_w, y_train_w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html(pd.DataFrame(mlp_bs.cv_results_).loc[:,['params', 'mean_test_score','rank_test_score']].sort_values(by='rank_test_score').head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test_w,mlp_bs.predict(X_test_w)), mean_absolute_error(y_test_w,mlp_bs.predict(X_test_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El MSE es coherente con el error de validación cruzada y es posiblemente ligeramente mejor que el de KNN, pero cada vez que ajustemos el MLP obtendremos un error diferente.\n",
    "\n",
    "Podemos tambien superponer las predicciones del test sobre el valor real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.plot(y_test_w[:500],'r');\n",
    "plt.plot(mlp_bs.predict(X_test_w[:500,:]),'b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberíamos explorar diferentes longitudes de ventana para ver cual es la que obtiene el mejor error, en este tipo de problemas este valor es otro hiperparámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Running time {timedelta(seconds=(time() - init_time))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
